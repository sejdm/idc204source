---
title: Questions during the 4th of March Zoom session
date: 27th March, 2020
---

During the Zoom session on the 4th of March, some of you had some questions that were not addressed in earlier posts. In this post, I have written more detailed and complete responses to those questions.

### Compare Turing machines with automata.

Here is a summary of each that highlights their differences.

**Deterministic finite state automata:** 
Languages that can be represented by regular expressions are recognized by deterministic finite state automata and all languages that can be recognized by deterministic finite state automata can be represented by regular expressions. The process stops when the entire input is read. It cannot re-read an input character. A string is accepted if it is an accept state *when it has read the entire input*.  

**Non-deterministic finite state automata:**
Non-deterministic finite state automata do **not** recognize any more languages. Therefore, non-deterministic finite state automata are as powerful as deterministic ones. All that is added is non-determinism so the process stops when the entire string is read, it cannot re-read an input, and a string is accepted if it is an accept state *when it has read the entire input*.  

**Pushdown automata:**
Languages generated by context free grammars are recognized by push-down automata and all languages that can be recognized by pushdown automata can be generated by some context free grammar. Push-down automata are provided with a stack. One can read only the last item pushed onto a stack; to read the second last one has to push the last one off the stack. However, this makes it more powerful than deterministic/non-deterministic finite state automata and the language consisting of strings of the form $0^n 1^n$ can be recognized by a push-down automata but not by an ordinary deterministic/non-deterministic finite state automaton. The process stops when the entire input is read. It cannot re-read an input character but it can store it on the stack (keep in mind its limitations). A string is accepted if it is an accept state *when it has read the entire input*.  

**Turing machines:** 
Turing machines are provided with a tape. The input is written on the tape. The machine can run back and forth through the tape. It is much more powerful than a push-down automaton or a simple deterministic / non-deterministic finite state automaton and the language consisting of strings of the form $a^nb^nc^n$ can be recognized by a Turing machine but not a push-down automaton or finite state automaton. The process stops when it reaches an accept or reject state and it can re-read / modify / add-to the input any number of times since the input is on the tape.

### Are there languages that a Turing machine cannot recognize?

Remember that the set of languages is uncountable because it is a power set of $\Sigma^*$. A Turing machine can be specified by a (finite) string, so the set of Turing machines is countable. If I correspond every Turing machine to the language it recognizes, there are bound to be many (in fact, uncountable) languages that are left out.

The same reasoning as above works for finite state automata as well as push-down automata. Of course, any subset of $\Sigma^*$ is technically a language but we want to find examples of saner languages that cannot be recognized. For finite state automata and push-down automata, we found concrete examples and used the pumping lemma to prove it. For Turing machines, the situation is trickier but later in the course we will see why it is impossible to build a Turing machine that will identify whether or a not a given Turing machine eventually will halt if a given string is provided as its input. Therefore, if I consider the language consisting of those pairs of the form $(T, s)$ such that $T$ will eventually halt when provided with $s$ as an input, then this language cannot be recognized by a Turing machine.

### Why finite states but an infinite tape?

One can give many reasons and each paragraph below deals with a different one. It is better to read this answer only if you are comfortable with the last two posts which introduced the concept of a Turing machine and outlined an example.

The transition function is at the heart of a finite state automaton, push-down automaton, or Turing machine. In each case, the finite state and alphabet together ensure that the domain is finite, allowing the function to be specified as a simple table. A particular Turing machine may need larger memory for larger inputs and is, therefore, provided with an infinite tape but if the states are infinite, you cannot even specify the complete design of the machine. 

In practice, we do not have infinite memory for any computation, but usually we have more than enough for the task at hand. Even if we temporarily run out of memory, it is simpler to add more memory. For instance, if we had a finite tape we may be forced to compromise and accept inputs from only a subset of the language. But if we want to accept bigger inputs, we just need to add more cells and lengthen the tape. On the other hand, consider what happens if we tried a similar compromise with a finite state automaton: if we try to recognize a non-regular language by bothering about only a finite subset of the language. Since all finite languages are regular, we can build a finite state automaton to recognize just that subset. However, every time we want to enhance that automaton to recognize an even bigger subset, the automaton will need a complete redesign! This is not at all as simple as increasing the length of the tape.

In fact, although technically we can design a finite state automaton to recognize a finite subset of a non-regular language, it will most likely require a huge number of states and will be little better than simply listing out all the elements of the language explicitly. The transition function will be tedious. But if we can build a Turing machine to recognize the entire language, although a finite tape may limit its use to a subset of the language, since larger inputs may at most require more tape with no change to the transition function, the transition function is likely to be significantly more sophisticated than merely listing out all the elements.

Furthermore, for a given computational task, if we assume unlimited memory, we can first establish whether or not it is possible to design a Turing machine at all for that task. Once that is done, we can study the maximum memory requirement (and even the time it takes) and in fact try to understand how that changes with the size of the input. We can know, for instance, whether a particular computation needs only a fixed amount of memory, even for large inputs, or if the size required grows exponentially if we increase the size of the input. This is precisely the concern of complexity theory, a subject that is tackled in your textbook although we may not have the time to touch upon it in this course. So we can say that by allowing an infinite tape, we can at least first tackle the problem of whether the computation is possible in theory, assuming as much memory available as needed, and study the impacts of limited memory separately (there is standard way to specify that, eg. the big O notation).

If the states are infinite, we cannot represent the transition function explicitly. One may ask why we insist that the transition function be defined explicitly. After all, we are used to many functions with infinite domains that we represent by using formulae. But we are trying to reduce computations to the basics. If you use a formula to represent a transition function with an infinite domain, you will have to specify how to compute that transition function so it may be a minor simplification at best but is not comparable to the reduction to basics achieved by Turing machines. So many computations, from arithmetic to sorting lists, in fact, anything that you can program, can be modelled using Turing machines. Yet, the differences between Turing machine is reduced to merely differences in the precise entries of the transition table. The form of the table, the way it is used by the machine along with the tape etc. are all the same for all Turing machine no matter what they model!

Finally, whenever you wonder why an alernative model is not used instead of the conventional Turing machine, the answer is either that your model is not as powerful or it is exactly as powerful, in which case choosing between your model and the conventional one is just a matter of taste. For instance, if you allowed transition functions with infinite domains, you would have to restrict attention to those functions which can be defined by at least finite amount of information so that you can at least specify the machine. So you might consider a Turing like machine which works just like an ordinary one except that its transition function is allowed to compute outputs using a conventional Turing machine.  However, since the workings of this machine can be simulated by a conventional Turing machine, this too will not be more powerful, despite enhancing its transition function. In fact, Turing, Church, and Goedel made completely independent attempts to define computable functions, but the remarkable fact is that each method, despite looking completely independent of each other, characterizes exactly the same class of functions as computable. The same holds true for subsequent attempts at characterizing computable functions (Read about the [Church-Turing thesis](https://en.wikipedia.org/wiki/Churchâ€“Turing_thesis), if you are interested). Therefore, although each method may individually feel a bit artificial, the fact that they characterize the same functions as computable makes one feel that they capture the concept of computation correctly. Yet another reason why the conventional definition of a Turing machine, with its finite set of states and infinite tape, ough to be the "right" definition even if there is more than one "right" definition.

